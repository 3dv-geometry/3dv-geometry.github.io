[{"layout":"default","title":"file1","content":"# file1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/","name":"file1.md","path":"3DV/Localization/file1.md","url":"/3DV/Localization/file1.html"},{"layout":"default","title":"file2","content":"# file2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/","name":"file2.md","path":"3DV/Localization/file2.md","url":"/3DV/Localization/file2.html"},{"layout":"default","title":"file3","content":"# file3\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/","name":"file3.md","path":"3DV/Localization/file3.md","url":"/3DV/Localization/file3.html"},{"permalink":"/3DV/Localization/folder2/","layout":"default","title":"I’m folder2","content":"# I'm folder2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/","name":"README.md","path":"3DV/Localization/folder2/README.md","url":"/3DV/Localization/folder2/"},{"layout":"default","title":"file1","content":"# file1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/","name":"file1.md","path":"3DV/Localization/folder2/file1.md","url":"/3DV/Localization/folder2/file1.html"},{"layout":"default","title":"file2","content":"# file2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/","name":"file2.md","path":"3DV/Localization/folder2/file2.md","url":"/3DV/Localization/folder2/file2.html"},{"layout":"default","title":"file3","content":"# file3\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/","name":"file3.md","path":"3DV/Localization/folder2/file3.md","url":"/3DV/Localization/folder2/file3.html"},{"permalink":"/3DV/Localization/folder2/folder1/","layout":"default","title":"I’m folder1","content":"# I'm folder1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/folder1/","name":"README.md","path":"3DV/Localization/folder2/folder1/README.md","url":"/3DV/Localization/folder2/folder1/"},{"layout":"default","title":"file1","content":"# file1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/folder1/","name":"file1.md","path":"3DV/Localization/folder2/folder1/file1.md","url":"/3DV/Localization/folder2/folder1/file1.html"},{"layout":"default","title":"file2","content":"# file2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/folder1/","name":"file2.md","path":"3DV/Localization/folder2/folder1/file2.md","url":"/3DV/Localization/folder2/folder1/file2.html"},{"layout":"default","title":"file3","content":"# file3\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/folder2/folder1/","name":"file3.md","path":"3DV/Localization/folder2/folder1/file3.md","url":"/3DV/Localization/folder2/folder1/file3.html"},{"permalink":"/3DV/Mapping/","layout":"default","title":"Mapping","content":"# Mapping\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/","name":"README.md","path":"3DV/Mapping/README.md","url":"/3DV/Mapping/"},{"layout":"default","title":"file1","content":"# file1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/","name":"file1.md","path":"3DV/Mapping/file1.md","url":"/3DV/Mapping/file1.html"},{"layout":"default","title":"file2","content":"# file2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/","name":"file2.md","path":"3DV/Mapping/file2.md","url":"/3DV/Mapping/file2.html"},{"layout":"default","title":"file3","content":"# file3\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/","name":"file3.md","path":"3DV/Mapping/file3.md","url":"/3DV/Mapping/file3.html"},{"permalink":"/3DV/Mapping/folder1/","layout":"default","title":"I’m folder1","content":"# I'm folder1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/folder1/","name":"README.md","path":"3DV/Mapping/folder1/README.md","url":"/3DV/Mapping/folder1/"},{"layout":"default","title":"file1","content":"# file1\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/folder1/","name":"file1.md","path":"3DV/Mapping/folder1/file1.md","url":"/3DV/Mapping/folder1/file1.html"},{"layout":"default","title":"file2","content":"# file2\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/folder1/","name":"file2.md","path":"3DV/Mapping/folder1/file2.md","url":"/3DV/Mapping/folder1/file2.html"},{"layout":"default","title":"file3","content":"# file3\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Mapping/folder1/","name":"file3.md","path":"3DV/Mapping/folder1/file3.md","url":"/3DV/Mapping/folder1/file3.html"},{"permalink":"//","layout":"default","title":"3D Vision and Geometry","content":"# 3D Vision and Geometry\n\nThis website is designed for paper sharing and discussion at the VCL lab in Peking University.\n\n\n## Topics\n\n- Shape Generation\n- Geometry Feature Learning\n- Single View Reconstruction\n- Neural 3D Renderer\n- Shape Analysis","dir":"/","name":"README.md","path":"README.md","url":"/"},{"permalink":"/3DV/Localization/","layout":"default","title":"Localization","content":"# Localization\n\nsource: `{{ page.path }}`\n","dir":"/3DV/Localization/","name":"README.md","path":"3DV/Localization/README.md","url":"/3DV/Localization/"},{"sort":1,"permalink":"/Shape%20Generation/","layout":"default","title":"Shape Generation","content":"<h1 id=\"shape-generation\">Shape Generation</h1>\n\n<p>Related works:</p>\n\n<ul>\n  <li><a href=\"/Shape%20Generation/Learning%20Representations%20and%20Generative%20Models%20for%203D%20Point%20Clouds.html\">Learning Representations and Generative Models for 3D Point Clouds</a></li>\n  <li><a href=\"/Shape%20Generation/PolyGen.html\">PolyGen: An Autoregressive Generative Model of 3D Meshes</a></li>\n  <li><a href=\"/Shape%20Generation/ParSeNet.html\">ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds</a></li>\n</ul>\n","dir":"/Shape%20Generation/","name":"README.md","path":"Shape Generation/README.md","url":"/Shape%20Generation/"},{"sort":1,"layout":"default","title":"DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction","content":"<h1 id=\"disn-deep-implicit-surface-network-for-high-quality-single-view-3d-reconstruction\">DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction</h1>\n\n<p>Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radomir Mech, Ulrich Neumann</p>\n\n<p>NIPS 2019 <a href=\"https://arxiv.org/abs/1904.04290\">PDF</a>|<a href=\"https://github.com/laughtervv/DISN\">Git</a></p>\n\n<p><img src=\"./disn-result.png\" />\nReconstructing 3D shapes from single-view images has been a long-standing research problem. In this paper, we present DISN, a Deep Implicit Surface Network which can generate a high-quality detail-rich 3D mesh from a 2D image by predicting the underlying signed distance fields. In addition to utilizing global image features, DISN predicts the projected location for each 3D point on the 2D image and extracts local features from the image feature maps. Combining global and local features significantly improves the accuracy of the signed distance field prediction, especially for the detail-rich areas. To the best of our knowledge, DISN is the first method that constantly captures details such as holes and thin structures present in 3D shapes from single-view images. DISN achieves the state-of-the-art single-view reconstruction performance on a variety of shape categories reconstructed from both synthetic and real images.</p>\n\n<ul>\n  <li>\n    <h3 id=\"network\">Network</h3>\n    <p><img src=\"./disn-network.png\" /></p>\n  </li>\n</ul>\n\n","dir":"/Single%20View%20Reconstruction/","name":"DISN- Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction.md","path":"Single View Reconstruction/DISN- Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction.md","url":"/Single%20View%20Reconstruction/DISN-%20Deep%20Implicit%20Surface%20Network%20for%20High-quality%20Single-view%203D%20Reconstruction.html"},{"sort":1,"layout":"default","title":"PointCNN","content":"<h1 id=\"pointcnn\">PointCNN</h1>\n\n<p>Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, and Baoquan Chen.</p>\n\n<p>NIPS 2018. <a href=\"https://github.com/yangyanli/PointCNN\">Github</a></p>\n\n","dir":"/Geometry%20Feature%20Learning/","name":"PointCNN.md","path":"Geometry Feature Learning/PointCNN.md","url":"/Geometry%20Feature%20Learning/PointCNN.html"},{"sort":1,"layout":"default","title":"Neural Rerendering in the Wild","content":"<h1 id=\"neural-rerendering-in-the-wild\">Neural Rerendering in the Wild</h1>\n\n<p>Moustafa Meshry, Dan B Goldman, Sameh Khamis, Hugues Hoppe, Rohit Pandey, Noah Snavely, Ricardo Martin-Brualla.</p>\n\n<p>CVPR 2019. <a href=\"https://arxiv.org/abs/1904.04290\">PDF</a></p>\n\n","dir":"/Differentiable%20Renderer/","name":"Neural Rerendering in the Wild.md","path":"Differentiable Renderer/Neural Rerendering in the Wild.md","url":"/Differentiable%20Renderer/Neural%20Rerendering%20in%20the%20Wild.html"},{"sort":1,"layout":"default","title":"Learning Representations and Generative Models for 3D Point Clouds","content":"<h1 id=\"learning-representations-and-generative-models-for-3d-point-clouds\">Learning Representations and Generative Models for 3D Point Clouds</h1>\n\n<p>Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, Leonidas Guibas</p>\n\n<p>ICML 2018. <a href=\"https://arxiv.org/abs/1707.02392\">PDF</a></p>\n\n","dir":"/Shape%20Generation/","name":"Learning Representations and Generative Models for 3D Point Clouds.md","path":"Shape Generation/Learning Representations and Generative Models for 3D Point Clouds.md","url":"/Shape%20Generation/Learning%20Representations%20and%20Generative%20Models%20for%203D%20Point%20Clouds.html"},{"sort":2,"layout":"default","title":"DFR: Differentiable Function Rendering for Learning 3D Generation from Images","content":"<h1 id=\"dfr-differentiable-function-rendering-for-learning-3d-generation-from-images\">DFR: Differentiable Function Rendering for Learning 3D Generation from Images</h1>\n\n<p>Jiahui Lyu   Bojian Wu   Dani Lischinski   Daniel Cohen-Or   Hui Huang</p>\n\n<p>ACM Transactions on Graphics (Proceedings of SIGGRAPH ASIA 2020)</p>\n\n<p><a href=\"https://vcc.tech/research/2020/DRT\">Project</a></p>\n\n","dir":"/Differentiable%20Renderer/","name":"DFR- Differentiable Function Rendering for Learning 3D Generation from Images.md","path":"Differentiable Renderer/DFR- Differentiable Function Rendering for Learning 3D Generation from Images.md","url":"/Differentiable%20Renderer/DFR-%20Differentiable%20Function%20Rendering%20for%20Learning%203D%20Generation%20from%20Images.html"},{"sort":2,"permalink":"/Single%20View%20Reconstruction/","layout":"default","title":"Single View Reconstruction","content":"<h1 id=\"single-view-reconstruction\">Single View Reconstruction</h1>\n\n<p>Related works:</p>\n\n<ul>\n  <li><a href=\"/Single%20View%20Reconstruction/DISN-%20Deep%20Implicit%20Surface%20Network%20for%20High-quality%20Single-view%203D%20Reconstruction.html\">DISN: Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction</a></li>\n  <li><a href=\"/Single%20View%20Reconstruction/Pixel2Mesh-%20Generating%203D%20Mesh%20Models%20from%20Single%20RGB%20Images.html\">Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images</a></li>\n</ul>\n","dir":"/Single%20View%20Reconstruction/","name":"README.md","path":"Single View Reconstruction/README.md","url":"/Single%20View%20Reconstruction/"},{"sort":2,"layout":"default","title":"Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images","content":"<h1 id=\"pixel2mesh-generating-3d-mesh-models-from-single-rgb-images\">Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images</h1>\n\n<p>Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, Yu-Gang Jiang</p>\n\n<p>ECCV 2018. <a href=\"https://arxiv.org/abs/1804.01654\">PDF</a></p>\n\n","dir":"/Single%20View%20Reconstruction/","name":"Pixel2Mesh- Generating 3D Mesh Models from Single RGB Images.md","path":"Single View Reconstruction/Pixel2Mesh- Generating 3D Mesh Models from Single RGB Images.md","url":"/Single%20View%20Reconstruction/Pixel2Mesh-%20Generating%203D%20Mesh%20Models%20from%20Single%20RGB%20Images.html"},{"sort":2,"layout":"default","title":"PointNet","content":"<h1 id=\"pointnet\">PointNet</h1>\n\n<p>Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas</p>\n\n<p>CVPR 2017. <a href=\"https://github.com/charlesq34/pointnet\">Github</a></p>\n\n","dir":"/Geometry%20Feature%20Learning/","name":"PointNet.md","path":"Geometry Feature Learning/PointNet.md","url":"/Geometry%20Feature%20Learning/PointNet.html"},{"sort":2,"layout":"default","title":"PolyGen: An Autoregressive Generative Model of 3D Meshes","content":"<h1 id=\"polygen-an-autoregressive-generative-model-of-3d-meshes\">PolyGen: An Autoregressive Generative Model of 3D Meshes</h1>\n\n<p>Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, Peter W. Battaglia (Google DeepMind)</p>\n\n<p><a href=\"https://arxiv.org/abs/2002.10880\">arxiv 2002.10880</a></p>\n\n<p>Generating n-gon mesh by using transformer to predict vertices and then the connecting edges.</p>\n\n<p>Major limitation: do not guarantee each face to be planar!</p>\n","dir":"/Shape%20Generation/","name":"PolyGen.md","path":"Shape Generation/PolyGen.md","url":"/Shape%20Generation/PolyGen.html"},{"sort":3,"layout":"default","title":"ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds","content":"<h1 id=\"parsenet-a-parametric-surface-fitting-network-for-3d-point-clouds\">ParSeNet: A Parametric Surface Fitting Network for 3D Point Clouds</h1>\n\n<p>Gopal Sharma, Difan Liu, Evangelos Kalogerakis, Subhransu Maji, Siddhartha Chaudhuri, Radomír Měch</p>\n\n<p><a href=\"https://hippogriff.github.io/parsenet/\">ECCV 2020</a></p>\n\n<p>Decompose a 3D point cloud into paramatric surface patches (including B-spline patches).</p>\n\n<p>Major limitation: predicted surface patches are infinite, i.e. do not predict surface boundraies explicitly.</p>\n","dir":"/Shape%20Generation/","name":"ParSeNet.md","path":"Shape Generation/ParSeNet.md","url":"/Shape%20Generation/ParSeNet.html"},{"sort":3,"layout":"default","title":"MeshCNN: A Network with an Edge","content":"<h1 id=\"meshcnn-a-network-with-an-edge\">MeshCNN: A Network with an Edge</h1>\n\n<p><a href=\"https://www.cs.tau.ac.il/~hanocka/\">Rana Hanocka</a>, <a href=\"http://pxcm.org/\">Amir Hertz</a>, <a href=\"https://www.cs.tau.ac.il/~noafish/\">Noa Fish</a>, <a href=\"http://web.eng.tau.ac.il/~raja\">Raja Giryes</a>, <a href=\"https://scholar.google.co.il/citations?user=nEpKS-8AAAAJ&amp;hl=en\">Shachar Fleishman</a> and <a href=\"https://www.cs.tau.ac.il/~dcor/\">Daniel Cohen-Or</a></p>\n\n<p><a href=\"https://ranahanocka.github.io/MeshCNN/\">SIGGRAPH 2019</a></p>\n\n<p>Define edge-based feature on mesh to enable convolution operation and use edge collapse to minic pooling operation.</p>\n\n","dir":"/Geometry%20Feature%20Learning/","name":"MeshCNN.md","path":"Geometry Feature Learning/MeshCNN.md","url":"/Geometry%20Feature%20Learning/MeshCNN.html"},{"sort":3,"permalink":"/Geometry%20Feature%20Learning/","layout":"default","title":"Geometry Feature Learning","content":"<h1 id=\"geometry-feature-learning\">Geometry Feature Learning</h1>\n\n<p>Related works:</p>\n\n<ul>\n  <li><a href=\"/Geometry%20Feature%20Learning/PointCNN.html\">PointCNN</a></li>\n  <li><a href=\"/Geometry%20Feature%20Learning/PointNet.html\">PointNet</a></li>\n  <li><a href=\"/Geometry%20Feature%20Learning/MeshCNN.html\">MeshCNN: A Network with an Edge</a></li>\n  <li><a href=\"/Geometry%20Feature%20Learning/UV-Net.html\">UV-Net: Learning from Curve-Networks and Solids</a></li>\n</ul>\n","dir":"/Geometry%20Feature%20Learning/","name":"README.md","path":"Geometry Feature Learning/README.md","url":"/Geometry%20Feature%20Learning/"},{"sort":4,"permalink":"/Differentiable%20Renderer/","layout":"default","title":"Differentiable Renderer","content":"<h1 id=\"differentiable-renderer\">Differentiable Renderer</h1>\n\n<p>Related works:</p>\n\n<ul>\n  <li><a href=\"/Differentiable%20Renderer/Neural%20Rerendering%20in%20the%20Wild.html\">Neural Rerendering in the Wild</a></li>\n  <li><a href=\"/Differentiable%20Renderer/DFR-%20Differentiable%20Function%20Rendering%20for%20Learning%203D%20Generation%20from%20Images.html\">DFR: Differentiable Function Rendering for Learning 3D Generation from Images</a></li>\n</ul>\n","dir":"/Differentiable%20Renderer/","name":"README.md","path":"Differentiable Renderer/README.md","url":"/Differentiable%20Renderer/"},{"sort":4,"layout":"default","title":"UV-Net: Learning from Curve-Networks and Solids","content":"<h1 id=\"uv-net-learning-from-curve-networks-and-solids\">UV-Net: Learning from Curve-Networks and Solids</h1>\n\n<p>Pradeep Kumar Jayaraman, Aditya Sanghi, Joseph Lambourne, Thomas Davies, Hooman Shayani, Nigel Morris</p>\n\n<p><a href=\"https://arxiv.org/abs/2006.10211\">arxiv 2006.10211</a></p>\n\n<p>A encoder for boundary representation by taking face-adjacent graph as topology and extracting face feature via UV mapping.</p>\n\n","dir":"/Geometry%20Feature%20Learning/","name":"UV-Net.md","path":"Geometry Feature Learning/UV-Net.md","url":"/Geometry%20Feature%20Learning/UV-Net.html"},{"sort":5,"permalink":"/3DV/","layout":"default","title":"3D Vision","content":"<h1 id=\"3d-vision\">3D Vision</h1>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>\n- [Mapping](/3DV/Mapping/)\n    - [file1](/3DV/Mapping/file1.html)\n    - [file2](/3DV/Mapping/file2.html)\n    - [file3](/3DV/Mapping/file3.html)\n    - [I’m folder1](/3DV/Mapping/folder1/)\n        - [file1](/3DV/Mapping/folder1/file1.html)\n        - [file2](/3DV/Mapping/folder1/file2.html)\n        - [file3](/3DV/Mapping/folder1/file3.html)\n- [Localization](/3DV/Localization/)\n    - [file1](/3DV/Localization/file1.html)\n    - [file2](/3DV/Localization/file2.html)\n    - [file3](/3DV/Localization/file3.html)\n    - [I’m folder2](/3DV/Localization/folder2/)\n        - [file1](/3DV/Localization/folder2/file1.html)\n        - [file2](/3DV/Localization/folder2/file2.html)\n        - [file3](/3DV/Localization/folder2/file3.html)\n        - [I’m folder1](/3DV/Localization/folder2/folder1/)\n            - [file1](/3DV/Localization/folder2/folder1/file1.html)\n            - [file2](/3DV/Localization/folder2/folder1/file2.html)\n            - [file3](/3DV/Localization/folder2/folder1/file3.html)\n</code></pre></div></div>\n\n<ul>\n  <li><a href=\"/3DV/Mapping/\">Mapping</a>\n    <ul>\n      <li><a href=\"/3DV/Mapping/file1.html\">file1</a></li>\n      <li><a href=\"/3DV/Mapping/file2.html\">file2</a></li>\n      <li><a href=\"/3DV/Mapping/file3.html\">file3</a></li>\n      <li><a href=\"/3DV/Mapping/folder1/\">I’m folder1</a>\n        <ul>\n          <li><a href=\"/3DV/Mapping/folder1/file1.html\">file1</a></li>\n          <li><a href=\"/3DV/Mapping/folder1/file2.html\">file2</a></li>\n          <li><a href=\"/3DV/Mapping/folder1/file3.html\">file3</a></li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li><a href=\"/3DV/Localization/\">Localization</a>\n    <ul>\n      <li><a href=\"/3DV/Localization/file1.html\">file1</a></li>\n      <li><a href=\"/3DV/Localization/file2.html\">file2</a></li>\n      <li><a href=\"/3DV/Localization/file3.html\">file3</a></li>\n      <li><a href=\"/3DV/Localization/folder2/\">I’m folder2</a>\n        <ul>\n          <li><a href=\"/3DV/Localization/folder2/file1.html\">file1</a></li>\n          <li><a href=\"/3DV/Localization/folder2/file2.html\">file2</a></li>\n          <li><a href=\"/3DV/Localization/folder2/file3.html\">file3</a></li>\n          <li><a href=\"/3DV/Localization/folder2/folder1/\">I’m folder1</a>\n            <ul>\n              <li><a href=\"/3DV/Localization/folder2/folder1/file1.html\">file1</a></li>\n              <li><a href=\"/3DV/Localization/folder2/folder1/file2.html\">file2</a></li>\n              <li><a href=\"/3DV/Localization/folder2/folder1/file3.html\">file3</a></li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n","dir":"/3DV/","name":"README.md","path":"3DV/README.md","url":"/3DV/"}]